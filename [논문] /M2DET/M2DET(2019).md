# **M2DET (2019)**  
---
A Single-Shot Object Detector based on Multi-Level Feature PyramidNetwork  
Review.LSJ, 2023.10.09  
## **Abstract**
* #### 기존의 FPN의 두 가지 문제점 지적
* #### detection 하기에 충분히 representative 못한 feature pyramid
* #### 객체의 외형에 따른 인식 성능 차이 발생  
* #### high-level feature map은 classification task와 복잡한 외형의 특징 포착에 적합
* #### low-level feature map은 localization task와 단순한 외형 파악에 적합  
* #### 한 이미지에 크기가 같지만 복잡도가 다른 두 객체가 있을 경우 둘 모두를 탐지 못할 가능성이 높음  

## **Introduction**  
### 서로 다른 크기와 외형의 복잡도를 가진 객체들을 detect 하기에 보다 효율적인 feature pyramid를 설계하는 MLFPN(Multi-Level Feature Pyramid Network) 제시  
* ### **FFM**  
  > #### backbone network로부터 low-level feature와 high-level feature을 합쳐 base feature map(multi-level feature map) 생성  
* ### **TUM**  
  > #### 서로 다른 scale의 feature map 생성  

   > #### FFMv2를 통해 base feature map과 이전 TUM의 output 중 scale이 가장 큰 feature map을 합쳐 다음 TUM에 입력  
* ### **SFAM**  
  > #### multi-level,multi-scale feature map을 scale-wise feature conatenation과 channel-wise attention 매커니즘을 통해 집계  

### 최종적으로 MLFPN과 SSD를 합쳐 강력한 end-to-end 형식의 one-stage detector 설계

## **Main Idea**  
  * ### **FFM**
  #### 서로 다른 level의 feature 합치는, multi-level feature pyramid 설계에 중요한 역할  
  ![image](https://github.com/sj990710/Thesis_Review/assets/127752372/87114066-1ed2-4c7c-a515-b31fc6dbbdf9)  

  + ### **FFMv1**  
    > #### backbone network로부터 두 개의 서로 다른 scale의 feature map을 추출  

    > #### 각각의 feature map에 conv 연산 적용하여 scale이 작은 feature map을 upsample한 후 concat하여 base feature map 생성
  + ### **FFMv2**  
    > #### 이전 TUM의 output 중 가장 scale이 큰 feature map과 base feature map을 융합해 다음 단계의 TUM으로 입력  
* ### **TUM**  
### 입력받은 feature map(최초의 base feature 혹은 이전 단계 TUM의 결과물)에 대해 multi-level feature map 생성 해당 논문에서는 8개의 TUM을 다룸
![image](https://github.com/sj990710/Thesis_Review/assets/127752372/c661d29d-45d9-4ed4-947e-7414d52387c1)  
  + ### **Encoder Network**  
    > #### 입력받은 feature map에 3x3 conv(stride=2) 연산을 적용해 scale이 다른 다수의 feature maps,({E1, E2, E3, E4, E5}) 출력
  + ### **Decoder Network**  
    > #### 가장 작은 scale의 feature map부터 upsamplig 후 이전 level의 feature map과의 융합을 반복해 multi-level feature maps, ({D1, D2, D3, D4, D5, D6}) 생성
* ### **SFAM**  
#### TUM들에 의해 생성된 multi-level, multi-scale feature map들을 multi-level feature pyramid로 구성  
  * ### **Scale-Wise Feature Concatentaion**  
    > #### 8개의 TUM으로부터 생성된 각각의 multi-level feature map들을 같은 scale끼리 concat시켜 6개의 multi-level, multi-scale feature map들로 재구성
![image](https://github.com/sj990710/Thesis_Review/assets/127752372/2513e353-dc45-47f2-88cb-cbe94e7275ea)  
  * ### **Channel-Wise Attention**  
    > #### Scale-Wise Feature Concatenation만으로는 충분히 adaptive한 feature map이 형성되지 않는다고 판단해 가장 효율적인 channel에 attention하도록 설계하는 작업  
    > 본 모듈에서는 Scale-Wise Feature Concatenation을 통해 출력된 feature map을 SE block에 입력하여 진행  
  ![image](https://github.com/sj990710/Thesis_Review/assets/127752372/5e0eee3e-046c-4575-8916-838aaccf5eee)  
    >  + ### **Squeeze step**  
    >  > #### 입력으로 들어온 HxWxC 크기의 feature map에 대해 Gloval Average Pooling 수행하여 각 channel을 하나의 숫자로만 표현  
    >  + ### **Excitation Step**  
    >  > #### 앞서 얻은 1x1xC 크기의 feature map에 2개의 fc layer를 적용해 channel 별 상대적 중요도 책정(Sigmoid를 이용해 0과 1 사이의 값 책정)  
    > + ### **Recalibration Step**  
    > > #### channel 별 중요도와 원본 feature map을 곱해 channel의 중요도 순으로 feature pyramid를 recalivrate(재보정)함  

## **Training M2DET** 
![image](https://github.com/sj990710/Thesis_Review/assets/127752372/0ed1a409-dc89-41ee-9470-b9fca659c202)  
* ### Extract two feature maps from backbone network(VGG or ResNet)  
  > #### 입력 받은 이미지로부터 서로 다른 scale을 가진 feature map 추출  
* ### Generate base feature map by FFMv1  
  > #### 두 feature map을 합쳐 하나의 base feature map 생성  
* ### Generate Multi-level, multi-scale features by jointly alternating FFMv1 and TUM  
  > #### base feature map을 첫 번째 TUM에 입력, multi-level, multi-scale feature maps 생성 생성된 feature map들 중 scale이 가장 큰 feature map과 base feature map을 FFMv2를 통해 융합후 다음 TUM에 입력. 이를 반복하여 총 8개의 multi-level, multi-scale feature maps 생성  
* ### Construct Final Pyramid by SFAM  
  > #### 각 6개씩 이루어진 8개의 TUM들의 output들을 scale-wise concatenation을 통해 scale 같은 feature map끼리 concat해 새로운 6개의 feature pyramid들 생성한 후 SE block을 통해 중요도에 따라 재배치
* ### Prediction by classification branch and bbox regression branch 
  > #### feature pyramid의 각 level 별 feature map들을 병렬로 구성된 두 개의 conv layer에 입력해 class score와 bbox regressor 획득

## **Experiments**  
![image](https://github.com/sj990710/Thesis_Review/assets/127752372/ec71ef93-d94d-44a9-8c33-c50efa188525)
## **Pros and Cos**
* ### **장점**
  > #### 다양한 크기의 객체를 효과적으로 검출할 수 있다  
  > #### 정밀도와 재현율 모두 우수하다  
  > #### 많은 객체를 검출하면서도 빠른 속도를 유지한다  
* ### **단점**
  > #### 모델이 복잡함
  > #### 데이터 요구량이 많다
  > #### 학습 시간이 오래 걸린다
